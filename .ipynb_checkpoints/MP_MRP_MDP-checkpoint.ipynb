{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from typing import TypeVar,Mapping, Set, Generic, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MP/MRP definitions and MRP Value Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Markov Process** = (finite) state set $S$ + transition probability matrix between states following the Markov property: $P(X_{t+1} = s|X_t = s') = P(X_{t+1} = s|X_t = s',...,X_0 = x)$<br>\n",
    "**Markov Reward Process** = Markov Process + Reward associated with each state + discount factor\n",
    "- Reward: $R_s = \\mathbb{E}[R_{t+1}|S_t = s]$ or $r(s',s)$, where $R_s = \\sum_{s' \\in S}r(s',s)p(s',s)$\n",
    "- Discount factor: $\\gamma$<br>\n",
    "\n",
    "**Return:** $G_t = R_{t+1} + \\gamma R_{t+2} + ... = \\sum^{\\infty}_{i=t+1}\\gamma^{i-t-1} R_i$ <br>\n",
    "**Value function**: $v(s) = \\mathbb{E}[G_{t}|S_t = s]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class design for MP\n",
    "**Write code to generate the stationary distribution for an MP** <br>\n",
    "We know that if $\\pi$ is the stationary distribution of an MP with transition matrix of A, then $\\pi = \\pi A$. <br>\n",
    "Equivalently, we find vector $\\pi$ as a left eigenvector of A with eigenvalue 1. Thus, finding the stationary distribution is equal to solving the eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "T = TypeVar(\"T\",str,int,float)\n",
    "\n",
    "# Identity helper function for str, int and float\n",
    "def ind(x: T, y: T):\n",
    "    if x == y or np.abs(x-y)<1e-5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Get state helper function\n",
    "def get_states_helper(in_graph: dict) -> dict:\n",
    "    state_list = list(in_graph.keys())\n",
    "    ind = range(len(state_list))\n",
    "    state = dict(zip(state_list,ind))\n",
    "    return state\n",
    "\n",
    "# Get transition matrix helper function\n",
    "def get_transition_helper(in_graph: dict) -> np.ndarray:\n",
    "    state = get_states_helper(in_graph)\n",
    "    tran_mat = np.zeros((len(state),len(state)))\n",
    "    for i, row in in_graph.items():\n",
    "        for j, prob in row.items():\n",
    "            ind_row = state[i]\n",
    "            ind_col = state[j]\n",
    "            if ind(tran_mat[ind_row,ind_col],0):\n",
    "                tran_mat[ind_row,ind_col] = prob\n",
    "    return tran_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sunny': 0, 'Cloudy': 1, 'Rainy': 2, 'Windy': 3}\n",
      "[[0.1  0.2  0.3  0.4 ]\n",
      " [0.25 0.25 0.3  0.2 ]\n",
      " [0.1  0.2  0.3  0.4 ]\n",
      " [0.25 0.25 0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "# Test helper functions\n",
    "Input = {'Sunny': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Windy': 0.4},\n",
    "         'Cloudy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.3, 'Windy': 0.2},\n",
    "         'Rainy': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Windy': 0.4},\n",
    "         'Windy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.25, 'Windy': 0.25}}\n",
    "print(get_states_helper(Input))\n",
    "print(get_transition_helper(Input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MP by Graph\n",
    "\"\"\"\n",
    "    E.g.,\n",
    "    Input = {'Sunny': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Cloudy': 0.4},\n",
    "             'Cloudy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.3, 'Cloudy': 0.2},\n",
    "             'Rainy': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Cloudy': 0.4},\n",
    "             'Windy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.25, 'Cloudy': 0.25}}\n",
    "    Meaning: Today's weather => tmr's weather\n",
    "\"\"\"\n",
    "\n",
    "class MP:\n",
    "    # Initiate state dict & transition matrix\n",
    "    def __init__(self, in_graph: dict) -> None:\n",
    "        self.graph = in_graph\n",
    "        state = get_states_helper(in_graph)\n",
    "        tran_mat = get_transition_helper(in_graph)\n",
    "        # Check transition matrix and match state set with transition probs\n",
    "        if np.linalg.norm(np.sum(tran_mat, axis = 1)- np.ones(tran_mat.shape[0]))>1e-5:\n",
    "            raise ValueError\n",
    "        elif len(state) != tran_mat.shape[0]:\n",
    "            raise ValueError\n",
    "        else:\n",
    "            self.state: dict = state\n",
    "            self.tran_mat: np.ndarray = tran_mat\n",
    "            \n",
    "    # Get all states\n",
    "    def get_states(self) -> set:\n",
    "        return self.state\n",
    "    \n",
    "    # Get the transition matirx\n",
    "    def get_tran_mat(self) -> np.ndarray:\n",
    "        return self.tran_mat\n",
    "    \n",
    "    # Compute stationary distribution using eigenvalue decomposition\n",
    "    def stationary_dist(self) -> np.array:\n",
    "        e_value, e_vec = np.linalg.eig(self.tran_mat.T)\n",
    "        out = np.array(e_vec[:, np.where(np.abs(e_value- 1.) < 1e-5)[0][0]])\n",
    "        out = out/np.sum(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sunny': 0, 'Cloudy': 1, 'Rainy': 2, 'Windy': 3}\n",
      "[[0.1  0.2  0.3  0.4 ]\n",
      " [0.25 0.25 0.3  0.2 ]\n",
      " [0.1  0.2  0.3  0.4 ]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "[0.18027211 0.22675737 0.2845805  0.30839002]\n"
     ]
    }
   ],
   "source": [
    "# Test class\n",
    "Input = {'Sunny': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Windy': 0.4},\n",
    "         'Cloudy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.3, 'Windy': 0.2},\n",
    "         'Rainy': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Windy': 0.4},\n",
    "         'Windy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.25, 'Windy': 0.25}}\n",
    "test_MP = MP(Input)\n",
    "print(test_MP.get_states())\n",
    "print(test_MP.get_tran_mat())\n",
    "print(test_MP.stationary_dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class design for MRP\n",
    "- Separately implement the $r(s,s')$ and the $R(s) = \\sum_{s'} p(s,s') * r(s,s')$ definitions of MRP\n",
    "- Write code to convert/cast the $r(s,s')$ definition of MRP to the $R(s)$ definition of MRP (put some thought into code design here)<br>\n",
    "\n",
    "**Given** $v(s) = \\mathbb{E}[G_{t}|S_t = s]= \\mathbb{E}[\\sum^{\\infty}_{i=0}\\gamma^{i} R_{t+i+1}|S_t = s]$ <br>\n",
    "**For state vector $S \\in \\mathbb{R}^d$** $v(S) = \\mathbb{E}[G_{t}|S_t] = \\mathbb{E}[\\sum^{\\infty}_{i=0}\\gamma^{i} P^i R_{t+1}|S_t] = \\mathbb{E}[(I-\\gamma P)^{-1}R_{t+1}|S_t]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reward helper function\n",
    "def convert_reward(_2nd_def_reward: dict, tran_mat: np.ndarray, state: dict) -> dict:\n",
    "    reward_mat = np.zeros((len(state),len(state)))\n",
    "    # Create reward matrix\n",
    "    for i, row in _2nd_def_reward.items():\n",
    "        for j, reward in row.items():\n",
    "            ind_row = state[i]\n",
    "            ind_col = state[j]\n",
    "            if ind(reward[ind_row,ind_col],0):\n",
    "                reward[ind_row,ind_col] = reward\n",
    "    # Cast to 1st def reward vector\n",
    "    reward_vec = np.diag(tran_mat.dot(reward_mat.T))\n",
    "    reward_dict = dict(zip(state.keys(),reward_vec))\n",
    "    return reward_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MRP by Graph\n",
    "\"\"\"\n",
    "    E.g.,\n",
    "    Input = {'Sunny': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Cloudy': 0.4},\n",
    "             'Cloudy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.3, 'Cloudy': 0.2},\n",
    "             'Rainy': {'Sunny': 0.1, 'Cloudy': 0.2, 'Rainy': 0.3, 'Cloudy': 0.4},\n",
    "             'Windy': {'Sunny': 0.25, 'Cloudy': 0.25, 'Rainy': 0.25, 'Cloudy': 0.25}}\n",
    "    state_reward = {'Rain': 1, 'Sunny': 2, 'Cloudy': 3, 'Windy': 4}\n",
    "    gamma = 0.5\n",
    "    Meaning: Today's weather => tmr's weather\n",
    "\"\"\"\n",
    "class MRP(MP):\n",
    "    \n",
    "    # Initiate state with reward and discount\n",
    "    def __init__(self, state_reward: dict, gamma: float) -> None:\n",
    "        if gamma <0 or gamma >1:\n",
    "            raise ValueError\n",
    "        else:\n",
    "            reward_vec = np.zeros(len(self.state))\n",
    "            for key, ind in self.state.items():\n",
    "                reward_vec[ind] = state_reward[key]\n",
    "            self.reward: np.ndarray = reward_vec\n",
    "            self.gamma: float = gamma\n",
    "    \n",
    "    # Compute value function R(s)\n",
    "    def value_func(self) -> float:\n",
    "        return np.linalg.inv(np.identity(len(self.state))-self.gamma*self.tran_mat).dot(self.reward)\n",
    "\n",
    "    # Compute value function r(s,s')\n",
    "    def value_func_2nd(self,_2nd_def_reward) -> float:\n",
    "        reward_dict = convert_reward(_2nd_def_reward)\n",
    "        reward_vec = np.zeros(len(self.state))\n",
    "        for key, ind in self.state.items():\n",
    "            reward_vec[ind] = reward_dict[key]\n",
    "        self.reward = reward_vec\n",
    "        return self.value_func()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
